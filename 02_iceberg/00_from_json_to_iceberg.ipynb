{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# From JSON to Time Travel in 10 Seconds\n",
    "\n",
    "This notebook demonstrates the power of Apache Iceberg in just a few lines of code:\n",
    "\n",
    "* Read JSON data and create an Iceberg table\n",
    "* Query the table instantly with SQL\n",
    "* Append more data and query again\n",
    "* Travel back in time to the first snapshot\n",
    "\n",
    "All of this happens in seconds, with full ACID transactions and automatic versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "import pyarrow as pa\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "\n",
    "# Setup paths and create Iceberg catalog\n",
    "warehouse_path = Path('../data/warehouse_quick_demo').absolute()\n",
    "warehouse_path.mkdir(parents=True, exist_ok=True)\n",
    "catalog_db = warehouse_path / 'catalog.db'\n",
    "catalog_db.unlink(missing_ok=True)  # Fresh start\n",
    "\n",
    "catalog = SqlCatalog(\n",
    "    'demo',\n",
    "    **{'uri': f'sqlite:///{catalog_db}', 'warehouse': f'file://{warehouse_path}'}\n",
    ")\n",
    "catalog.create_namespace('demo')\n",
    "print(\"âœ… Catalog ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read first 100K events from JSON and create Iceberg table\n",
    "jsonl_file = Path('../data/input/events.jsonl')\n",
    "\n",
    "with jsonl_file.open('r') as f:\n",
    "    # Read first 100K records\n",
    "    data = [json.loads(line) for i, line in enumerate(f) if i < 100000]\n",
    "\n",
    "arrow_table = pa.Table.from_pylist(data)\n",
    "iceberg_table = catalog.create_table('demo.events', schema=pa.schema(arrow_table.schema))\n",
    "iceberg_table.append(arrow_table)\n",
    "\n",
    "print(f\"âœ… Created table with {len(data):,} events (Snapshot 1)\")\n",
    "\n",
    "# Query with Daft\n",
    "df = daft.read_iceberg(iceberg_table)\n",
    "print(\"\\nTop 5 event types:\")\n",
    "daft.sql(\"\"\"\n",
    "    SELECT type, COUNT(*) as count\n",
    "    FROM df\n",
    "    GROUP BY type\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6g7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append next 100K events\n",
    "with jsonl_file.open('r') as f:\n",
    "    # Skip first 100K, read next 100K\n",
    "    data = [json.loads(line) for i, line in enumerate(f) if 100000 <= i < 200000]\n",
    "\n",
    "arrow_table = pa.Table.from_pylist(data)\n",
    "iceberg_table.append(arrow_table)\n",
    "\n",
    "print(f\"âœ… Appended {len(data):,} more events (Snapshot 2)\")\n",
    "\n",
    "# Query again - now includes both batches\n",
    "df = daft.read_iceberg(iceberg_table)\n",
    "print(\"\\nTotal events after append:\")\n",
    "daft.sql(\"SELECT COUNT(*) as total FROM df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time travel: go back to first snapshot\n",
    "history = iceberg_table.history()\n",
    "first_snapshot_id = history[0].snapshot_id\n",
    "\n",
    "print(f\"â° Time traveling to Snapshot {first_snapshot_id}\\n\")\n",
    "\n",
    "# Read data as it was in the first snapshot\n",
    "df_past = daft.read_iceberg(iceberg_table, snapshot_id=first_snapshot_id)\n",
    "print(\"Events in first snapshot:\")\n",
    "daft.sql(\"SELECT COUNT(*) as total FROM df_past\").show()\n",
    "\n",
    "print(\"\\nðŸŽ‰ You just:\")\n",
    "print(\"  â€¢ Created a versioned table from JSON\")\n",
    "print(\"  â€¢ Queried it with SQL\")\n",
    "print(\"  â€¢ Appended new data\")\n",
    "print(\"  â€¢ Traveled back in time\")\n",
    "print(\"\\nAll with ACID transactions, no data rewrites, in seconds!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
