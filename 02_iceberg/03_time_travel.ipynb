{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Time travel and snapshots\n",
    "\n",
    "Iceberg's **time travel** feature enables you to query data as it existed in the past.\n",
    "In this notebook, we'll explore:\n",
    "\n",
    "* **Understanding snapshots**: What they are and how they work\n",
    "* **Time travel queries**: Query data from specific points in time\n",
    "* **Snapshot operations**: Inspect, compare, and manage snapshots\n",
    "* **Rollback**: Undo changes by rolling back to previous snapshots\n",
    "* **Branching and tagging**: Create named references to snapshots\n",
    "* **Snapshot expiration**: Clean up old snapshots to save storage\n",
    "\n",
    "By the end, you'll be able to use Iceberg's time travel features for debugging, auditing, and data recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import daft\n",
    "import pyarrow as pa\n",
    "from pathlib import Path\n",
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import compare_snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_table",
   "metadata": {},
   "source": [
    "## Setup: Create a table with rich history\n",
    "\n",
    "Let's create a table with multiple snapshots to demonstrate time travel features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_path = Path('../data/warehouse_time_travel').absolute()\n",
    "shutil.rmtree(warehouse_path, ignore_errors=True)\n",
    "warehouse_path.mkdir(parents=True, exist_ok=True)\n",
    "catalog_db = warehouse_path / 'catalog.db'\n",
    "catalog_db.unlink(missing_ok=True)\n",
    "\n",
    "catalog = SqlCatalog(\n",
    "    'time_travel_demo',\n",
    "    **{'uri': f'sqlite:///{catalog_db}', 'warehouse': f'file://{warehouse_path}'}\n",
    ")\n",
    "catalog.create_namespace('demo')\n",
    "print(\"âœ… Catalog initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_history",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = daft.read_json('../data/input/events.jsonl')\n",
    "\n",
    "# Snapshot 1: Initial load (\"Week 1\")\n",
    "print(\"Creating Snapshot 1: Initial load\")\n",
    "df_week1 = df_events.limit(20000)\n",
    "arrow_table = df_week1.to_arrow()\n",
    "events_table = catalog.create_table('demo.events', schema=pa.schema(arrow_table.schema))\n",
    "events_table.append(arrow_table)\n",
    "time.sleep(1)  # Small delay to ensure snapshots have different timestamps\n",
    "\n",
    "# Snapshot 2: \"Week 2\" data\n",
    "print(\"Creating Snapshot 2: \\\"Week 2\\\" data\")\n",
    "df_week2 = df_events.offset(20000).limit(20000)\n",
    "arrow_table = df_week2.to_arrow()\n",
    "events_table.append(arrow_table)\n",
    "time.sleep(1)  # Ensure distinct snapshot timestamps\n",
    "\n",
    "# Snapshot 3: Delete \"bad data\" (discovered data quality issue)\n",
    "print(\"Creating Snapshot 3: Delete OperationMode events (data quality fix)\")\n",
    "events_table.delete(\"type = 'OperationMode'\")\n",
    "time.sleep(1)  # Ensure distinct snapshot timestamps\n",
    "\n",
    "# Snapshot 4: \"Week 3\" data\n",
    "print(\"Creating Snapshot 4: \\\"Week 3\\\" data\")\n",
    "df_week3 = df_events.offset(40000).limit(20000)\n",
    "arrow_table = df_week3.to_arrow()\n",
    "events_table.append(arrow_table)\n",
    "\n",
    "print(f\"\\nâœ… Created table with {len(events_table.history())} snapshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding_snapshots",
   "metadata": {},
   "source": [
    "## Understanding snapshots for time travel\n",
    "\n",
    "Recall from the previous notebooks that each write operation creates a new **snapshot** - an immutable view of the table at that point in time. In the metadata deep dive, we explored how snapshots are stored in the metadata JSON with properties like `snapshot_id`, `timestamp_ms`, `manifest_list`, and operation `summary`.\n",
    "\n",
    "For time travel, two additional snapshot properties become crucial:\n",
    "\n",
    "* **parent_snapshot_id**: Links to the previous snapshot, forming a chain of history\n",
    "* **sequence_number**: Monotonically increasing number that orders snapshots\n",
    "\n",
    "This chain structure is what enables time travel:\n",
    "* Walk backwards through history to any previous state\n",
    "* Understand the exact order of operations\n",
    "* Identify which snapshot was current at any given time\n",
    "\n",
    "Let's inspect our snapshots and see this chain in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list_snapshots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get snapshot history\n",
    "history = events_table.snapshots()\n",
    "\n",
    "print(f\"Total snapshots: {len(history)}\\n\")\n",
    "print(f\"{'Snap':<5} {'Timestamp':<20} {'Operation':<10} {'Records':<12} {'Files'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, snapshot in enumerate(history, 1):\n",
    "    timestamp = datetime.fromtimestamp(snapshot.timestamp_ms / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    operation = snapshot.summary.operation.value if snapshot.summary else 'N/A'\n",
    "\n",
    "    # Get statistics from summary\n",
    "    props = snapshot.summary.additional_properties if snapshot.summary else {}\n",
    "    total_records = props.get('total-records', props.get('added-records', 'N/A'))\n",
    "    total_files = props.get('total-data-files', props.get('added-data-files', 'N/A'))\n",
    "\n",
    "    print(f\"{i:<5} {timestamp:<20} {operation:<10} {str(total_records):<12} {total_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect_snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a specific snapshot in detail\n",
    "snap1 = history[3]\n",
    "print(f\"Snapshot 1 Details:\\n\")\n",
    "print(f\"ID: {snap1.snapshot_id}\")\n",
    "print(f\"Timestamp: {datetime.fromtimestamp(snap1.timestamp_ms / 1000)}\")\n",
    "print(f\"Sequence number: {snap1.sequence_number if hasattr(snap1, 'sequence_number') else 'N/A'}\")\n",
    "print(f\"Parent snapshot: {snap1.parent_snapshot_id if hasattr(snap1, 'parent_snapshot_id') else 'None (first snapshot)'}\")\n",
    "\n",
    "if snap1.summary:\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  Operation: {snap1.summary.operation.value}\")\n",
    "    if snap1.summary.additional_properties:\n",
    "        for key, value in sorted(snap1.summary.additional_properties.items()):\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "time_travel_queries",
   "metadata": {},
   "source": [
    "## Time travel queries\n",
    "\n",
    "To query historical versions of your data, switch to a previous snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query_by_snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query current state\n",
    "df_current = daft.read_iceberg(events_table)\n",
    "print(\"Current state:\")\n",
    "daft.sql(\"SELECT COUNT(*) as total_events FROM df_current\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Snapshot 1 (\"Week 1\")\n",
    "snapshot1_id = history[0].snapshot_id\n",
    "df_snap1 = daft.read_iceberg(events_table, snapshot_id=snapshot1_id)\n",
    "print(f\"\\nSnapshot 1 (\\\"Week 1\\\") (ID: {snapshot1_id}):\")\n",
    "daft.sql(\"SELECT COUNT(*) as total_events FROM df_snap1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ddbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Snapshot 2 (\"Week 2\")\n",
    "snapshot2_id = history[1].snapshot_id\n",
    "df_snap2 = daft.read_iceberg(events_table, snapshot_id=snapshot2_id)\n",
    "print(f\"\\nSnapshot 2 (\\\"Week 2\\\") (ID: {snapshot2_id}):\")\n",
    "daft.sql(\"SELECT COUNT(*) as total_events FROM df_snap2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timestamp_query",
   "metadata": {},
   "source": [
    "Since each snapshot includes a timestamp, you can find the snapshot that was valid at a particular time as well. This is useful for questions like:\n",
    "\n",
    "* \"Show me the data as of yesterday at 3pm\"\n",
    "* \"What did the monthly report see on March 1st?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "use_cases",
   "metadata": {},
   "source": [
    "### Time travel use cases\n",
    "\n",
    "Time travel is useful for:\n",
    "\n",
    "1. **Debugging**: \"What data did the broken job see?\"\n",
    "2. **Auditing**: \"Show me all changes in the last 24 hours\"\n",
    "3. **Reproducing reports**: \"Re-run the quarterly report with the exact data it used\"\n",
    "4. **Data recovery**: \"Restore deleted records from yesterday\"\n",
    "5. **Testing**: \"Compare results before and after a schema change\"\n",
    "\n",
    "Let's demonstrate a debugging scenario: We deleted OperationMode events in Snapshot 3. Let's verify that they existed before and are gone now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debugging_scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before deletion (Snapshot 2)\n",
    "snap2_id = history[1].snapshot_id\n",
    "df_before = daft.read_iceberg(events_table, snapshot_id=snap2_id)\n",
    "print(\"Before deletion (Snapshot 2):\")\n",
    "daft.sql(\"\"\"\n",
    "    SELECT\n",
    "        SUM(CASE WHEN type = 'OperationMode' THEN 1 ELSE 0 END) as operation_mode_events,\n",
    "        COUNT(*) as total\n",
    "    FROM df_before\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15504651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After deletion (Snapshot 3)\n",
    "snap3_id = history[2].snapshot_id\n",
    "df_after = daft.read_iceberg(events_table, snapshot_id=snap3_id)\n",
    "print(\"\\nAfter deletion (Snapshot 3):\")\n",
    "daft.sql(\"\"\"\n",
    "    SELECT\n",
    "        SUM(CASE WHEN type = 'OperationMode' THEN 1 ELSE 0 END) as operation_mode_events,\n",
    "        COUNT(*) as total\n",
    "    FROM df_after\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"\\nâœ… Time travel confirmed the deletion happened in Snapshot 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rollback",
   "metadata": {},
   "source": [
    "## Rollback: Undoing changes\n",
    "\n",
    "Rollback reverts the table to a previous snapshot. This is like `git reset` - it makes a previous snapshot current.\n",
    "\n",
    "**Important**: Rollback doesn't delete snapshots or data. It just changes which snapshot is \"current\".\n",
    "\n",
    "**Key limitation**: Rollback only works with **ancestor snapshots** - you can only roll back to snapshots that are in the direct lineage of the current snapshot. Think of it like Git: you can't \"rollback\" to a future commit. This means rollback is designed for **recovering from mistakes** (undoing bad commits), not for freely navigating between arbitrary snapshot states. For navigation, use time travel queries instead.\n",
    "\n",
    "### When to use rollback\n",
    "\n",
    "* Bad data was loaded\n",
    "* A bug in the ingestion pipeline\n",
    "* Accidental deletion\n",
    "* Testing: rollback after test, then re-apply operations to return to latest\n",
    "\n",
    "Let's rollback to before the deletion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rollback_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current state (after deletion)\n",
    "df = daft.read_iceberg(events_table)\n",
    "daft.sql(\"\"\"\n",
    "    SELECT\n",
    "        SUM(CASE WHEN type = 'OperationMode' THEN 1 ELSE 0 END) as operation_mode_events,\n",
    "        COUNT(*) as total\n",
    "    FROM df\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16393c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rollback to Snapshot 2 (before deletion)\n",
    "snap2_id = history[1].snapshot_id\n",
    "print(f\"\\nRolling back to Snapshot 2 (ID: {snap2_id})...\")\n",
    "print(f\"Note: This changes the 'current' snapshot but doesn't delete snapshots 3 and 4.\\n\")\n",
    "events_table.manage_snapshots().rollback_to_snapshot(snap2_id).commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_table = catalog.load_table('demo.events') # Reload the table to get the updated state\n",
    "df = daft.read_iceberg(events_table)\n",
    "result = daft.sql(\"\"\"\n",
    "    SELECT\n",
    "        SUM(CASE WHEN type = 'OperationMode' THEN 1 ELSE 0 END) as operation_mode_events,\n",
    "        COUNT(*) as total\n",
    "    FROM df\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"\\nâœ… Rollback successful! OperationMode events are back.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rollback_history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check history after rollback - use snapshots() for full snapshot objects\n",
    "history = events_table.snapshots()\n",
    "current_snap_id = events_table.current_snapshot().snapshot_id\n",
    "\n",
    "print(\"Snapshot history after rollback:\\n\")\n",
    "for i, snap in enumerate(history, 1):\n",
    "    is_current = snap.snapshot_id == current_snap_id\n",
    "    marker = \" â† CURRENT\" if is_current else \"\"\n",
    "    timestamp = datetime.fromtimestamp(snap.timestamp_ms / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"Snapshot {i}: {snap.snapshot_id} @ {timestamp}{marker}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "branching_tagging",
   "metadata": {},
   "source": [
    "Note: All snapshots still exist. We just changed which one is 'current'.\n",
    "\n",
    "Since we rolled back for demonstration purposes, let's restore the table to its latest state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_tags",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_snapshot_id = history[-1].snapshot_id\n",
    "events_table.manage_snapshots().set_current_snapshot(\n",
    "    snapshot_id=latest_snapshot_id\n",
    ").commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db366f",
   "metadata": {},
   "source": [
    "## Branching and tagging\n",
    "\n",
    "Iceberg supports **named references** to snapshots:\n",
    "\n",
    "* **Tags**: Immutable pointers to snapshots (like Git tags)\n",
    "  - Use for: releases, quarterly reports, milestones\n",
    "  - Example: `quarterly-report-2024-Q4`\n",
    "\n",
    "* **Branches**: Mutable pointers that can advance (like Git branches)\n",
    "  - Use for: experimental changes, staging environments\n",
    "  - Example: `experiment-new-schema`\n",
    "\n",
    "Note: Contrary to Git, the scope of a tag or branch in the Iceberg standard is only a single table (unless you are using Project Nessie as catalog).\n",
    "\n",
    "### Creating tags\n",
    "\n",
    "Tags are useful for marking important snapshots that you want to keep forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload history and create tags for important snapshots\n",
    "history = events_table.snapshots()\n",
    "snap1_id = history[0].snapshot_id\n",
    "snap2_id = history[1].snapshot_id\n",
    "\n",
    "# Tag the initial load (snapshot_id, tag_name)\n",
    "events_table.manage_snapshots().create_tag(snap1_id, 'initial-load').commit()\n",
    "print(f\"âœ… Created tag 'initial-load' â†’ Snapshot {snap1_id}\")\n",
    "\n",
    "# Tag week 2\n",
    "events_table.manage_snapshots().create_tag(snap2_id, 'week-2-complete').commit()\n",
    "print(f\"âœ… Created tag 'week-2-complete' â†’ Snapshot {snap2_id}\")\n",
    "\n",
    "# Reload the table to get the updated state\n",
    "events_table = catalog.load_table('demo.events')\n",
    "\n",
    "# List available tags\n",
    "print(\"\\nAvailable tags in the table:\")\n",
    "for ref_name, ref in events_table.metadata.refs.items():\n",
    "    print(f\"  â€¢ {ref_name} â†’ Snapshot {ref.snapshot_id}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by tag name\n",
    "# Note: daft.read_iceberg() requires integer snapshot IDs, not tag names\n",
    "# So we need to resolve the tag to its snapshot ID first\n",
    "initial_load_ref = events_table.metadata.refs.get('initial-load')\n",
    "if initial_load_ref:\n",
    "    initial_load_snapshot_id = initial_load_ref.snapshot_id\n",
    "    df_initial = daft.read_iceberg(events_table, snapshot_id=initial_load_snapshot_id)\n",
    "    print(f\"Querying 'initial-load' tag (snapshot {initial_load_snapshot_id}):\")\n",
    "    daft.sql(\"SELECT COUNT(*) as total FROM df_initial\").show()\n",
    "else:\n",
    "    print(\"âš ï¸  Tag 'initial-load' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query another tag\n",
    "week2_ref = events_table.metadata.refs.get('week-2-complete')\n",
    "if week2_ref:\n",
    "    week2_snapshot_id = week2_ref.snapshot_id\n",
    "    df_week2 = daft.read_iceberg(events_table, snapshot_id=week2_snapshot_id)\n",
    "    print(f\"Querying 'week-2-complete' tag (snapshot {week2_snapshot_id}):\")\n",
    "    daft.sql(\"SELECT COUNT(*) as total FROM df_week2\").show()\n",
    "else:\n",
    "    print(\"âš ï¸  Tag 'week-2-complete' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e127b5",
   "metadata": {},
   "source": [
    "### Creating branches\n",
    "\n",
    "Branches allow you to make experimental changes without affecting the main timeline. Unlike tags, branches are mutable - new commits can be made to a branch.\n",
    "\n",
    "This allows you to:\n",
    "\n",
    "* Develop experimental features in isolation\n",
    "* Test schema changes without affecting the main table\n",
    "* Create staging environments for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "branch_concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a branch from the current snapshot\n",
    "current_snapshot_id = events_table.current_snapshot().snapshot_id\n",
    "\n",
    "events_table.manage_snapshots().create_branch(\n",
    "    snapshot_id=current_snapshot_id,\n",
    "    branch_name='experimental',\n",
    "    min_snapshots_to_keep=2  # Keep at least 2 snapshots on this branch\n",
    ").commit()\n",
    "\n",
    "print(f\"âœ… Created branch 'experimental' from snapshot {current_snapshot_id}\")\n",
    "\n",
    "# Reload table and list all references (tags and branches)\n",
    "events_table = catalog.load_table('demo.events')\n",
    "print(\"\\nAll references (tags and branches):\")\n",
    "for ref_name, ref in events_table.metadata.refs.items():\n",
    "    ref_type = \"branch\" if ref_name not in ['main', 'initial-load', 'week-2-complete'] else \"tag\" if ref_name != 'main' else \"main branch\"\n",
    "    print(f\"  â€¢ {ref_name} ({ref_type}) â†’ Snapshot {ref.snapshot_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d75c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the branch - like tags, we need to resolve it to a snapshot ID\n",
    "print(\"\\nQuerying the 'experimental' branch:\")\n",
    "experimental_ref = events_table.metadata.refs.get('experimental')\n",
    "if experimental_ref:\n",
    "    experimental_snapshot_id = experimental_ref.snapshot_id\n",
    "    df_experimental = daft.read_iceberg(events_table, snapshot_id=experimental_snapshot_id)\n",
    "    print(f\"Branch snapshot ID: {experimental_snapshot_id}\")\n",
    "    daft.sql(\"SELECT COUNT(*) as total FROM df_experimental\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“ Writing to the experimental branch...\")\n",
    "df_test = df_events.offset(60000).limit(1000)\n",
    "test_data = df_test.to_arrow()\n",
    "\n",
    "# Append to the experimental branch (not main)\n",
    "events_table.append(test_data, branch='experimental')\n",
    "\n",
    "print(f\"âœ… Appended {len(test_data)} records to 'experimental' branch\")\n",
    "\n",
    "# Reload and check the branches\n",
    "events_table = catalog.load_table('demo.events')\n",
    "print(\"\\nAfter writing to experimental branch:\")\n",
    "main_ref = events_table.metadata.refs.get('main')\n",
    "experimental_ref = events_table.metadata.refs.get('experimental')\n",
    "print(f\"  â€¢ main branch â†’ Snapshot {main_ref.snapshot_id}\")\n",
    "print(f\"  â€¢ experimental branch â†’ Snapshot {experimental_ref.snapshot_id}\")\n",
    "if main_ref.snapshot_id != experimental_ref.snapshot_id:\n",
    "    print(\"  âœ“ Branches now point to different snapshots!\")\n",
    "\n",
    "# Query both branches to see the difference\n",
    "df_main = daft.read_iceberg(events_table, snapshot_id=main_ref.snapshot_id)\n",
    "df_exp = daft.read_iceberg(events_table, snapshot_id=experimental_ref.snapshot_id)\n",
    "\n",
    "print(\"\\nRecord counts:\")\n",
    "print(f\"  Main branch: {daft.sql('SELECT COUNT(*) as count FROM df_main').to_pydict()['count'][0]:,}\")\n",
    "print(f\"  Experimental branch: {daft.sql('SELECT COUNT(*) as count FROM df_exp').to_pydict()['count'][0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "snapshot_expiration",
   "metadata": {},
   "source": [
    "## Snapshot expiration\n",
    "\n",
    "Snapshots are retained forever by default. This enables unlimited time travel, but:\n",
    "\n",
    "* **Storage costs**: Old data files accumulate\n",
    "* **Metadata overhead**: Manifest lists grow\n",
    "* **Cleanup complexity**: Hard to know what's still needed\n",
    "\n",
    "**Snapshot expiration** in Iceberg has two phases:\n",
    "\n",
    "1. **Expire snapshots**: Removes old snapshots from metadata\n",
    "2. **Delete orphan files**: Removes unreferenced data files (separate operation)\n",
    "\n",
    "PyIceberg currently implements **phase 1 only** - it removes snapshot metadata but leaves data files intact. Deleting orphan files is [currently under implementation](https://github.com/apache/iceberg-python/pull/1958).\n",
    "\n",
    "Let's demonstrate snapshot metadata expiration only for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "before_expiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current snapshots in the table:\")\n",
    "history = events_table.snapshots()\n",
    "for i, snap in enumerate(history, 1):\n",
    "    timestamp = datetime.fromtimestamp(snap.timestamp_ms / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    is_tagged = any(ref.snapshot_id == snap.snapshot_id for ref in events_table.metadata.refs.values())\n",
    "    tag_marker = \" [TAGGED - Protected]\" if is_tagged else \"\"\n",
    "    print(f\"  Snapshot {i}: {snap.snapshot_id} @ {timestamp}{tag_marker}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(history)} snapshots\")\n",
    "\n",
    "# Run snapshot expiration\n",
    "# This will remove snapshot metadata for old snapshots\n",
    "# Tagged snapshots are automatically protected\n",
    "print(\"\\nðŸ§¹ Running snapshot metadata expiration...\")\n",
    "\n",
    "# Expire snapshots older than 2 seconds for demonstration purposes.\n",
    "# Note: Protected snapshots (tags, branches) are automatically excluded\n",
    "events_table.maintenance.expire_snapshots().older_than(\n",
    "    datetime.now() - timedelta(seconds=2)\n",
    ").commit()\n",
    "\n",
    "# Reload and check what remains\n",
    "events_table = catalog.load_table('demo.events')\n",
    "history = events_table.snapshots()\n",
    "\n",
    "print(\"Snapshots after expiration:\")\n",
    "for i, snap in enumerate(history, 1):\n",
    "    timestamp = datetime.fromtimestamp(snap.timestamp_ms / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    is_tagged = any(ref.snapshot_id == snap.snapshot_id for ref in events_table.metadata.refs.values())\n",
    "    tag_marker = \" [TAGGED - Protected]\" if is_tagged else \"\"\n",
    "    print(f\"  Snapshot {i}: {snap.snapshot_id} @ {timestamp}{tag_marker}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(history)} snapshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "review",
   "metadata": {},
   "source": [
    "## Review questions\n",
    "\n",
    "**What role do `parent_snapshot_id` and `sequence_number` play in time travel?**\n",
    "   - How does the parent chain enable walking backwards through history?\n",
    "   - Why does Iceberg need both properties?\n",
    "\n",
    "**When would you use time travel queries vs rollback?**\n",
    "   - What's the difference in their purpose and effect?\n",
    "   - Can you rollback to any snapshot?\n",
    "\n",
    "**How is Iceberg time travel different from traditional backup files?**\n",
    "   - Think about query capabilities, storage efficiency, and metadata overhead.\n",
    "   - What advantages does the snapshot model provide?\n",
    "\n",
    "**What happens to data files when you rollback?**\n",
    "   - Does it affect the snapshot or data files?\n",
    "   - Are files deleted or moved?\n",
    "\n",
    "**What does deleting a tag actually remove?**\n",
    "   - What actually changes in the metadata?\n",
    "   - If you delete a tag, can you still access that snapshot?\n",
    "\n",
    "**What is removed with snapshot expiration?**\n",
    "   - What is actually removed?\n",
    "   - What is safe?\n",
    "\n",
    "**What's the difference between tags and branches in Iceberg?**\n",
    "   - Compare it with Git.\n",
    "   - What happens to the main branch when you write to a different branch?\n",
    "\n",
    "**What could be reasons to separate metadata expiration from data deletion?**\n",
    "   - What happens exactly in the phases?\n",
    "   - What are the safety implications?\n",
    "   - Can data files be orphaned in another way? Think of transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenge",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "### Simulate a bad load and recover\n",
    "\n",
    "1. Query the current table and note the total record count\n",
    "2. Append some test data to the events table\n",
    "3. Verify the new data appears in the table\n",
    "4. \"Discover\" it's bad data and rollback to the previous snapshot\n",
    "5. Verify the table is back to the original state\n",
    "6. **Bonus**: Can you \"redo\" the bad load by advancing to the future snapshot?\n",
    "\n",
    "### Find which snapshot changed something\n",
    "\n",
    "We deleted OperationMode events somewhere in our history:\n",
    "\n",
    "1. Loop through all snapshots and query each one\n",
    "2. Check how many OperationMode events exist at each snapshot\n",
    "3. Identify exactly which snapshot performed the deletion\n",
    "4. How many OperationMode events were deleted?\n",
    "5. **Hint**: Compare the count before and after each snapshot\n",
    "\n",
    "### Work with branches for isolated development\n",
    "\n",
    "1. Create a new branch called `quality-check` from the current snapshot\n",
    "2. Write some test data to the `quality-check` branch (don't modify main)\n",
    "3. Query both `main` and `quality-check` branches\n",
    "4. Compare the record counts to verify isolation\n",
    "5. **Bonus**: What happens if you try to rollback the main branch to a snapshot on the quality-check branch?\n",
    "\n",
    "### Compare snapshots\n",
    "\n",
    "1. Use the `compare_snapshots()` helper function (already imported)\n",
    "2. Compare the two tagged snapshots: 'initial-load' and 'week-2-complete'\n",
    "3. What operations occurred between them?\n",
    "4. How many files and records were added?\n",
    "\n",
    "### Recovery from accidental deletion\n",
    "\n",
    "Simulate accidentally deleting important records:\n",
    "\n",
    "1. Delete all events where `type = 'Alarm'` from the main branch\n",
    "2. Use time travel to query the previous snapshot and count how many Alarm events existed\n",
    "3. Export those alarm events to a variable (hint: `.to_pydict()` or `.to_arrow()`)\n",
    "4. Rollback to restore the table\n",
    "5. **Bonus**: Instead of rollback, could you re-insert just the deleted records?\n",
    "\n",
    "### Create an audit trail report\n",
    "\n",
    "1. For each snapshot in the history, extract:\n",
    "   - Timestamp\n",
    "   - Operation type\n",
    "   - Records added/deleted\n",
    "   - Total records in that snapshot\n",
    "2. Display as a formatted table or dataframe\n",
    "3. Calculate: What's the net change in records from first to last snapshot?\n",
    "4. **Bonus**: Create a visualization showing record count over time\n",
    "\n",
    "### Understand expiration protection\n",
    "\n",
    "After the expiration we ran earlier:\n",
    "\n",
    "1. List which snapshots survived expiration and which were removed\n",
    "2. Explain why each protected snapshot was not expired\n",
    "3. What would happen if you:\n",
    "   - Removed all tags?\n",
    "   - Ran expiration with `older_than(datetime.now())`?\n",
    "4. **Bonus**: Try creating a tag, running expiration, then removing the tag. Can you still access that snapshot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored Iceberg's time travel capabilities:\n",
    "\n",
    "* **Snapshots**: Immutable views of the table at specific points in time\n",
    "  - Created by every write operation\n",
    "  - Form a chain with parent pointers\n",
    "  - Contain operation summaries and statistics\n",
    "\n",
    "* **Time travel**: Query historical data\n",
    "  - By snapshot ID (precise)\n",
    "  - By timestamp (user-friendly)\n",
    "  - Use cases: debugging, auditing, reproducing reports\n",
    "\n",
    "* **Rollback**: Undo changes\n",
    "  - Non-destructive (snapshots remain)\n",
    "  - Changes which snapshot is \"current\"\n",
    "  - Can be undone by rolling back again\n",
    "\n",
    "* **Tags and branches**: Named references\n",
    "  - Tags: Immutable, for milestones\n",
    "  - Branches: Mutable, for experiments\n",
    "  - PyIceberg supports writing to branches directly (since 0.10)\n",
    "  - Enable human-readable snapshot references\n",
    "\n",
    "* **Snapshot expiration**: Clean up old metadata\n",
    "  - PyIceberg: Removes snapshot metadata only, but currently cannot clean data files (use Spark for that or wait for the pull request :-) ).\n",
    "  - Time-based or count-based policies\n",
    "  - Respects tags and retention settings\n",
    "\n",
    "### Key takeaways\n",
    "\n",
    "1. **Time travel is cheap**: Just metadata changes, no data copying\n",
    "2. **Rollback is safe**: Can always roll forward again\n",
    "3. **Tags preserve history**: Tagged snapshots never expire\n",
    "4. **Branches enable isolation**: Write experimental changes without affecting main\n",
    "5. **Metadata vs data cleanup**: PyIceberg separates these for safety\n",
    "6. **Audit trail is automatic**: Every change is recorded\n",
    "\n",
    "Next, we will look at schema evolution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
